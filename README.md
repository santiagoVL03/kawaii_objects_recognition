# ğŸ¯ IA de SegmentaciÃ³n de ImÃ¡genes para DetecciÃ³n de Ropa

## ğŸ“‹ DescripciÃ³n del Proyecto

Este proyecto implementa una **Inteligencia Artificial de SegmentaciÃ³n SemÃ¡ntica** para la detecciÃ³n y clasificaciÃ³n automÃ¡tica de prendas de vestir en imÃ¡genes. El sistema utiliza una arquitectura **U-Net** personalizada entrenada con TensorFlow/Keras para identificar y segmentar dos tipos de prendas:

- ğŸ”´ **Prendas de Arriba** (camisetas, blusas, suÃ©teres, etc.)
- ğŸ”µ **Prendas de Abajo** (pantalones, faldas, shorts, etc.)

## ğŸ—ï¸ Arquitectura del Sistema

### 1. **Pipeline de Procesamiento YOLO (PreparaciÃ³n de Datos)**
- DetecciÃ³n inicial de objetos usando modelos YOLO pre-entrenados
- ExtracciÃ³n y filtrado de regiones de interÃ©s (ROIs) de prendas
- GeneraciÃ³n automÃ¡tica de datasets balanceados

### 2. **Red Neuronal U-Net Personalizada**
- Arquitectura encoder-decoder optimizada para segmentaciÃ³n semÃ¡ntica
- 32 filtros base con capacidad de escalamiento
- Salida de 3 clases: Fondo, Prenda Arriba, Prenda Abajo

## ğŸš€ CaracterÃ­sticas Principales

âœ… **Eficiencia en Memoria**: Uso de `tf.data.Dataset` para manejo inteligente de grandes volÃºmenes de datos
âœ… **Soporte CUDA**: Entrenamiento acelerado por GPU con TensorFlow
âœ… **PredicciÃ³n en Tiempo Real**: Script de inferencia para imÃ¡genes individuales
âœ… **VisualizaciÃ³n Avanzada**: Overlay colorizado para resultados de segmentaciÃ³n
âœ… **Callbacks Inteligentes**: Early stopping, reducciÃ³n de learning rate automÃ¡tica

## ğŸ“ Estructura del Proyecto

```
kawaii_objects_recognition/
â”œâ”€â”€ segmentation_dataset_balanced/     # Dataset principal
â”‚   â”œâ”€â”€ train/
â”‚   â”‚   â”œâ”€â”€ images/                   # ImÃ¡genes de entrenamiento
â”‚   â”‚   â””â”€â”€ masks/                    # MÃ¡scaras de segmentaciÃ³n
â”‚   â””â”€â”€ proccess/                     # Resultados y previsualizaciones
â”œâ”€â”€ unet/                             # CÃ³digo principal U-Net
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ dataset_robust.py         # Carga eficiente de datos
â”‚   â”‚   â””â”€â”€ model.py                  # Arquitectura U-Net
â”‚   â”œâ”€â”€ train_with_robust_dataset.py  # Script de entrenamiento principal
â”‚   â”œâ”€â”€ predict.py                    # PredicciÃ³n en imÃ¡genes nuevas
â”‚   â””â”€â”€ model/                        # Modelos entrenados
â”‚       â””â”€â”€ best_model.keras          # Mejor modelo guardado
â”œâ”€â”€ yolo_images/                      # ImÃ¡genes de prueba YOLO
â””â”€â”€ README.md                         # Este archivo
```

## âš™ï¸ InstalaciÃ³n y ConfiguraciÃ³n

### 1. **Prerequisitos del Sistema**
```bash
# Verificar GPU NVIDIA (opcional pero recomendado)
nvidia-smi

# Verificar CUDA instalado
nvcc --version
```

### 2. **Crear Entorno Virtual**
```bash
cd kawaii_objects_recognition
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# Ã³ .venv\Scripts\activate  # Windows
```

### 3. **Instalar Dependencias**
```bash
pip install tensorflow[and-cuda]
pip install matplotlib pillow numpy scikit-learn
```

### 4. **ConfiguraciÃ³n CUDA (para GPU)**
```bash
# Instalar CUDA Toolkit
sudo apt install nvidia-cuda-toolkit

# Verificar instalaciÃ³n
nvcc --version
python -c "import tensorflow as tf; print('GPUs:', tf.config.list_physical_devices('GPU'))"
```

## ğŸ¯ Uso del Sistema

### **Entrenamiento del Modelo**

#### OpciÃ³n 1: Entrenamiento Completo (Recomendado)
```bash
cd unet
python train_with_robust_dataset.py
```

**CaracterÃ­sticas del entrenamiento:**
- ğŸ“Š Carga eficiente de datos con `tf.data.Dataset`
- ğŸ§  Uso optimizado de memoria RAM
- ğŸš€ AceleraciÃ³n por GPU automÃ¡tica
- ğŸ“ˆ Monitoreo en tiempo real con callbacks inteligentes
- ğŸ’¾ Guardado automÃ¡tico del mejor modelo

#### ConfiguraciÃ³n Personalizada
```python
# Editar en train_with_robust_dataset.py
batch_size = 16      # Ajustar segÃºn RAM/GPU disponible
epochs = 25          # NÃºmero de Ã©pocas de entrenamiento
learning_rate = 1e-4 # Tasa de aprendizaje inicial
validation_split = 0.2 # 20% para validaciÃ³n
```

### **PredicciÃ³n en ImÃ¡genes Nuevas**

```bash
cd unet
python predict.py
```

**Funcionalidades de predicciÃ³n:**
- ğŸ–¼ï¸ Carga automÃ¡tica del mejor modelo entrenado
- ğŸ¨ VisualizaciÃ³n con colores brillantes y llamativos
- ğŸ” Tres vistas: Original, MÃ¡scara, Overlay
- ğŸ’¾ Guardado automÃ¡tico de resultados

#### PredicciÃ³n Personalizada
```python
# Usar imagen especÃ­fica
predict_image(
    model_path="model/best_model.keras",
    image_path="ruta/a/tu/imagen.jpg"
)
```

## ğŸ§  Detalles TÃ©cnicos

### **Arquitectura U-Net Personalizada**
```python
# ConfiguraciÃ³n del modelo
input_size = (128, 128, 3)  # ImÃ¡genes RGB de 128x128
n_filters = 32              # Filtros base
n_classes = 3               # Fondo + 2 tipos de prenda
```

### **Pipeline de Datos Eficiente**
- **Carga Lazy**: Solo carga imÃ¡genes cuando se necesitan
- **Procesamiento Paralelo**: Usa todos los cores disponibles
- **Prefetching**: Prepara el siguiente batch mientras entrena
- **AugmentaciÃ³n**: Rotaciones y flips automÃ¡ticos

### **Optimizaciones de Memoria**
```python
# Antes (problemÃ¡tico)
X, y = load_all_images()  # âŒ Carga todo en RAM

# Ahora (eficiente)
dataset = tf.data.Dataset.from_generator(...)  # âœ… Carga bajo demanda
dataset = dataset.batch(16).prefetch(tf.data.AUTOTUNE)
```

## ğŸ“Š MÃ©tricas y Resultados

### **MÃ©tricas de Entrenamiento**
- **Loss Function**: Sparse Categorical Crossentropy
- **MÃ©trica Principal**: Accuracy
- **Optimizador**: Adam con learning rate adaptativo
- **Callbacks**: Early Stopping, Reduce LR on Plateau

### **Visualizaciones Generadas**
1. **training_dataset_preview.png**: Preview del dataset de entrenamiento
2. **training_history_complete.png**: GrÃ¡ficos detallados de entrenamiento
3. **training_summary.png**: Resumen visual del proceso
4. **prediction_result.png**: Resultado de predicciÃ³n con overlay

## ğŸ› ï¸ SoluciÃ³n de Problemas Comunes

### **Error: "Out of Memory" durante entrenamiento**
```bash
# Reducir batch_size
batch_size = 8  # En lugar de 16
```

### **Error: "CUDA out of memory"**
```python
# Forzar uso de CPU
import os
os.environ['CUDA_VISIBLE_DEVICES'] = '-1'
```

### **Error: "libdevice not found"**
```bash
# Crear enlace simbÃ³lico
sudo ln -s /usr/lib/cuda/libdevice.10.bc ./libdevice.10.bc
```

### **Modelo no converge**
```python
# Ajustar learning rate
learning_rate = 1e-5  # MÃ¡s conservador
```

## ğŸ”® PrÃ³ximas Mejoras

- [ ] **Aumento de Dataset**: Incorporar mÃ¡s categorÃ­as de ropa
- [ ] **Transfer Learning**: Usar modelos pre-entrenados como backbone
- [ ] **DetecciÃ³n en Video**: Procesamiento en tiempo real
- [ ] **API REST**: Servicio web para predicciones
- [ ] **OptimizaciÃ³n Mobile**: VersiÃ³n TensorFlow Lite

## ğŸ“ˆ Casos de Uso

### **Comercio ElectrÃ³nico**
- ClasificaciÃ³n automÃ¡tica de inventario
- Mejora de motores de bÃºsqueda visual
- Recomendaciones personalizadas

### **Realidad Aumentada**
- Prueba virtual de prendas
- Aplicaciones de moda interactivas

### **AnÃ¡lisis de Tendencias**
- Estudios de mercado automatizados
- AnÃ¡lisis de preferencias de consumo

## ğŸ¤ Contribuciones

Este proyecto forma parte de un trabajo universitario de investigaciÃ³n en Computer Vision y Deep Learning. Las contribuciones y mejoras son bienvenidas.

### **CÃ³mo Contribuir**
1. Fork del repositorio
2. Crear branch para nueva feature
3. Implementar mejoras con pruebas
4. Pull request con descripciÃ³n detallada

## ğŸ“œ Licencia

Proyecto desarrollado con fines acadÃ©micos y de investigaciÃ³n.

## ğŸ‘¨â€ğŸ’» Autor

**Santiago** - Estudiante de IngenierÃ­a en Computer Vision y Deep Learning
- Universidad: [Tu Universidad]
- Proyecto: Reconocimiento Kawaii de Objetos con SegmentaciÃ³n SemÃ¡ntica

---

## ğŸš€ Quick Start

```bash
# Clonar y configurar
git clone [tu-repo]
cd kawaii_objects_recognition
python -m venv .venv && source .venv/bin/activate

# Instalar dependencias
pip install tensorflow matplotlib pillow numpy scikit-learn

# Entrenar modelo
cd unet && python train_with_robust_dataset.py

# Hacer predicciÃ³n
python predict.py
```

**Â¡Tu IA de segmentaciÃ³n de ropa estÃ¡ lista para usar!** ğŸ‰ğŸ‘•ğŸ‘–